{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35572c74-f069-4c9a-b6c5-406f548b5bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import email\n",
    "import csv\n",
    "import pandas as pd\n",
    "from email import policy\n",
    "from bs4 import BeautifulSoup\n",
    "import hashlib\n",
    "from email.utils import parseaddr\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3313363-f746-490e-83cf-f1dc4d2f9fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories of email datasets\n",
    "directories = [\n",
    "    \"rawdata/Test dataset/easy_ham\",\n",
    "    \"rawdata/Test dataset/easy_ham 2\",\n",
    "    \"rawdata/Test dataset/hard_ham 3\",\n",
    "    \"rawdata/Test dataset/spam\",\n",
    "    \"rawdata/Test dataset/spam 3\",\n",
    "    \"rawdata/Test dataset/spam 4\",\n",
    "    \"rawdata/Test dataset/Phishing corpus/20051114\",\n",
    "    \"rawdata/Test dataset/Phishing corpus/phishing0\",\n",
    "    \"rawdata/Test dataset/Phishing corpus/phishing2\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c78eafc7-601a-4d1a-9223-6b7b774fd7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MBOX path\n",
    "mbox_path = \"rawdata/Test dataset/phishing1.mbox\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5c823dc-9870-4911-ac44-f43b8d851b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract sender name, username, and domain\n",
    "\n",
    "def extract_sender_components(sender_raw):\n",
    "    name, email_addr = parseaddr(sender_raw)\n",
    "    username, domain = (\"\", \"\")\n",
    "    if \"@\" in email_addr:\n",
    "        username, domain = email_addr.split(\"@\", 1)\n",
    "    return name.strip(), username.strip(), domain.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9e59421-4511-474b-8aeb-9bf0d4c286d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract URLs and split components\n",
    "\n",
    "def extract_urls_with_parts(text):\n",
    "    urls = re.findall(r'http[s]?://\\S+', text)\n",
    "    url_data = []\n",
    "    for url in urls:\n",
    "        try:\n",
    "            cleaned_url = re.sub(r'[\\]\\)>\"\\']+$', '', url)\n",
    "            parsed = urlparse(cleaned_url)\n",
    "            url_data.append({\n",
    "                \"url\": cleaned_url,\n",
    "                \"domain\": parsed.netloc,\n",
    "                \"path\": parsed.path,\n",
    "                \"query\": parsed.query\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to parse URL: {url}, Error: {e}\")\n",
    "    return url_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "675477da-3665-480d-9355-353328708a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract attachments\n",
    "\n",
    "def get_attachment_hashes(msg):\n",
    "    hashes = []\n",
    "    for part in msg.walk():\n",
    "        if part.get_content_disposition() == \"attachment\":\n",
    "            payload = part.get_payload(decode=True)\n",
    "            if payload:\n",
    "                hashes.append(hashlib.sha256(payload).hexdigest())\n",
    "    return hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c88a4f4a-8219-4310-b026-746eeb13e912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract additional headers from body_text (if present)\n",
    "def extract_additional_headers_and_clean_body(body):\n",
    "    header_sender = \"\"\n",
    "    message_id = \"\"\n",
    "\n",
    "    lines = body.splitlines()\n",
    "    cleaned_lines = []\n",
    "    for line in lines:\n",
    "        if line.lower().startswith(\"from:\"):\n",
    "            header_sender = line.split(\":\", 1)[1].strip()\n",
    "        elif line.lower().startswith(\"message-id:\"):\n",
    "            message_id = line.split(\":\", 1)[1].strip()\n",
    "        elif line.lower().startswith(\"date:\") or line.lower().startswith(\"sent:\"):\n",
    "            continue  # Remove timestamp or sent line\n",
    "        elif re.match(r'^>\\s*$', line):\n",
    "            continue  # Remove quoted empty lines\n",
    "        elif re.match(r'^(from|date|subject|to|cc|bcc):', line.strip(), re.IGNORECASE):\n",
    "            continue  # Remove common header lines in body\n",
    "        else:\n",
    "            cleaned_lines.append(line)\n",
    "\n",
    "    cleaned_body = \"\\n\".join(cleaned_lines).strip()\n",
    "    return header_sender, message_id, cleaned_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1cb49e0-1083-4ac3-9082-312b26e37bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine email safety\n",
    "def determine_mail_safety(directory):\n",
    "    directory = directory.lower()\n",
    "    if \"easy_ham\" in directory or \"hard_ham\" in directory:\n",
    "        return 1\n",
    "    elif \"spam\" in directory or \"phishing\" in directory:\n",
    "        return 0\n",
    "    return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "772d5e03-59bc-4b48-8b95-df048e57a9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse single email\n",
    "def parse_eml(file_path, email_id, directory):\n",
    "    with open(file_path, \"r\", encoding=\"latin-1\") as f:\n",
    "        msg = email.message_from_file(f, policy=policy.compat32)\n",
    "\n",
    "    raw_sender = msg.get(\"From\", \"Unknown\")\n",
    "    name, username, domain = extract_sender_components(raw_sender)\n",
    "\n",
    "    # Additional headers\n",
    "    subject = msg.get(\"Subject\", \"\")\n",
    "    reply_to = msg.get(\"Reply-To\", \"\")\n",
    "    x_mailer = msg.get(\"X-Mailer\", \"\")\n",
    "    return_path = msg.get(\"Return-Path\", \"\")\n",
    "    received = msg.get(\"Received\", \"\")\n",
    "\n",
    "    # Extract body\n",
    "    body = \"\"\n",
    "    if msg.is_multipart():\n",
    "        for part in msg.walk():\n",
    "            if part.get_content_type() == \"text/plain\":\n",
    "                body = part.get_payload(decode=True).decode(errors=\"ignore\")\n",
    "                break\n",
    "            elif part.get_content_type() == \"text/html\" and not body:\n",
    "                body = BeautifulSoup(part.get_payload(decode=True), \"html.parser\").get_text()\n",
    "    else:\n",
    "        body = msg.get_payload(decode=True).decode(errors=\"ignore\")\n",
    "\n",
    "    header_sender, message_id, cleaned_body = extract_additional_headers_and_clean_body(body)\n",
    "\n",
    "    urls = extract_urls_with_parts(cleaned_body)\n",
    "    attachments = get_attachment_hashes(msg)\n",
    "    mail_is_safe = determine_mail_safety(directory)\n",
    "\n",
    "    entries = []\n",
    "\n",
    "    for url_info in urls:\n",
    "        entries.append({\n",
    "            \"id\": email_id,\n",
    "            \"name\": name,\n",
    "            \"username\": username,\n",
    "            \"mail_domain\": domain,\n",
    "            \"header_sender\": header_sender,\n",
    "            \"message_id\": message_id,\n",
    "            \"subject\": subject,\n",
    "            \"reply_to\": reply_to,\n",
    "            \"x_mailer\": x_mailer,\n",
    "            \"return_path\": return_path,\n",
    "            \"received\": received,\n",
    "            \"body_text\": cleaned_body,\n",
    "            \"body_count_of_words\": len(cleaned_body.split()),\n",
    "            \"body_length\": len(cleaned_body),\n",
    "            \"has_url\": 1,\n",
    "            \"url_count\": len(urls),\n",
    "            \"url\": url_info[\"url\"],\n",
    "            \"url_domain\": url_info[\"domain\"],\n",
    "            \"url_path\": url_info[\"path\"],\n",
    "            \"url_query\": url_info[\"query\"],\n",
    "            \"url_is_safe\": \"\",\n",
    "            \"has_attachment\": 1 if attachments else 0,\n",
    "            \"attachment_count\": len(attachments),\n",
    "            \"attachment_hash\": \"\",\n",
    "            \"attachment_is_safe\": \"\",\n",
    "            \"mail_is_safe\": mail_is_safe\n",
    "        })\n",
    "\n",
    "    for hash_val in attachments:\n",
    "        entries.append({\n",
    "            \"id\": email_id,\n",
    "            \"name\": name,\n",
    "            \"username\": username,\n",
    "            \"mail_domain\": domain,\n",
    "            \"header_sender\": header_sender,\n",
    "            \"message_id\": message_id,\n",
    "            \"subject\": subject,\n",
    "            \"reply_to\": reply_to,\n",
    "            \"x_mailer\": x_mailer,\n",
    "            \"return_path\": return_path,\n",
    "            \"received\": received,\n",
    "            \"body_text\": cleaned_body,\n",
    "            \"body_count_of_words\": len(cleaned_body.split()),\n",
    "            \"body_length\": len(cleaned_body),\n",
    "            \"has_url\": 1 if urls else 0,\n",
    "            \"url_count\": len(urls),\n",
    "            \"url\": \"\",\n",
    "            \"url_domain\": \"\",\n",
    "            \"url_path\": \"\",\n",
    "            \"url_query\": \"\",\n",
    "            \"url_is_safe\": \"\",\n",
    "            \"has_attachment\": 1,\n",
    "            \"attachment_count\": len(attachments),\n",
    "            \"attachment_hash\": hash_val,\n",
    "            \"attachment_is_safe\": \"\",\n",
    "            \"mail_is_safe\": mail_is_safe\n",
    "        })\n",
    "\n",
    "    return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cf6121c-2d54-45cd-9769-01d8cfafe6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_mbox(mbox_path, start_id, mail_is_safe=0):\n",
    "    import mailbox\n",
    "    from bs4 import BeautifulSoup\n",
    "\n",
    "    mbox = mailbox.mbox(mbox_path)\n",
    "    rows = []\n",
    "    email_id = start_id\n",
    "\n",
    "    for msg in mbox:\n",
    "        try:\n",
    "            sender_info = extract_sender_components(msg)\n",
    "\n",
    "            body = \"\"\n",
    "            if msg.is_multipart():\n",
    "                for part in msg.walk():\n",
    "                    content_type = part.get_content_type()\n",
    "                    if content_type == \"text/plain\":\n",
    "                        body += part.get_payload(decode=True).decode(errors=\"ignore\")\n",
    "                    elif content_type == \"text/html\" and not body:\n",
    "                        body += BeautifulSoup(part.get_payload(decode=True), \"html.parser\").get_text()\n",
    "            else:\n",
    "                body = msg.get_payload(decode=True).decode(errors=\"ignore\")\n",
    "\n",
    "            headers, cleaned_body = extract_additional_headers_and_clean_body(body)\n",
    "            urls = extract_urls_with_parts(cleaned_body)\n",
    "            attachments = get_attachment_hashes(msg)\n",
    "\n",
    "            max_items = max(len(urls), len(attachments), 1)\n",
    "            for i in range(max_items):\n",
    "                url_data = urls[i] if i < len(urls) else {\"url\": \"\", \"domain\": \"\", \"path\": \"\", \"query\": \"\"}\n",
    "                attachment = attachments[i] if i < len(attachments) else \"\"\n",
    "\n",
    "                rows.append({\n",
    "                    \"id\": email_id,\n",
    "                    \"name\": sender_info[\"name\"],\n",
    "                    \"username\": sender_info[\"username\"],\n",
    "                    \"mail_domain\": sender_info[\"mail_domain\"],\n",
    "                    **headers,\n",
    "                    \"body_text\": cleaned_body,\n",
    "                    \"body_count_of_words\": len(cleaned_body.split()),\n",
    "                    \"body_length\": len(cleaned_body),\n",
    "                    \"has_url\": 1 if urls else 0,\n",
    "                    \"url_count\": len(urls),\n",
    "                    \"url\": url_data[\"url\"],\n",
    "                    \"url_domain\": url_data[\"domain\"],\n",
    "                    \"url_path\": url_data[\"path\"],\n",
    "                    \"url_query\": url_data[\"query\"],\n",
    "                    \"url_is_safe\": \"\",\n",
    "                    \"has_attachment\": 1 if attachments else 0,\n",
    "                    \"attachment_count\": len(attachments),\n",
    "                    \"attachment_hash\": attachment,\n",
    "                    \"attachment_is_safe\": \"\",\n",
    "                    \"mail_is_safe\": mail_is_safe\n",
    "                })\n",
    "            email_id += 1\n",
    "        except Exception as e:\n",
    "            email_id += 1\n",
    "    return rows, email_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5525df65-f255-4f1c-9d5e-64e1a315a794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_emails():\n",
    "    output_file = \"data/test_email.csv\"\n",
    "    fieldnames = [\n",
    "        \"id\", \"name\", \"username\", \"mail_domain\", \"header_sender\", \"message_id\",\n",
    "        \"subject\", \"reply_to\", \"x_mailer\", \"return_path\", \"received\",\n",
    "        \"body_text\", \"body_count_of_words\", \"body_length\",\n",
    "        \"has_url\", \"url_count\", \"url\", \"url_domain\", \"url_path\", \"url_query\", \"url_is_safe\",\n",
    "        \"has_attachment\", \"attachment_count\", \"attachment_hash\", \"attachment_is_safe\",\n",
    "        \"mail_is_safe\"\n",
    "    ]\n",
    "\n",
    "    email_id = 1\n",
    "\n",
    "    with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Process EML files\n",
    "        for directory in directories:\n",
    "            for file in sorted(os.listdir(directory)):\n",
    "                file_path = os.path.join(directory, file)\n",
    "                if os.path.isfile(file_path):\n",
    "                    entries = parse_eml(file_path, email_id, directory)\n",
    "                    for entry in entries:\n",
    "                        writer.writerow(entry)\n",
    "                    email_id += 1\n",
    "\n",
    "        # Process single MBOX file\n",
    "        mbox_rows, email_id = parse_mbox(mbox_path, email_id, mail_is_safe=0)\n",
    "        for row in mbox_rows:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(f\"Test dataset feature extraction complete. Output saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e952a4d2-ef25-4224-919a-14e58870ff0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset feature extraction complete. Output saved to data/test_email.csv\n"
     ]
    }
   ],
   "source": [
    "# Run the process\n",
    "process_emails()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d8f73bdb-7b0c-42b9-b153-47f62b49c4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phishing Emails: 10496\n",
      "1. With URLs: 10001\n",
      "2. Without URLs: 495\n",
      "3. With Attachments: 28\n",
      "4. Without Attachments: 10468\n",
      "\n",
      "Safe Emails: 43189\n",
      "1. With URLs: 43117\n",
      "2. Without URLs: 72\n",
      "3. With Attachments: 32\n",
      "4. Without Attachments: 43157\n",
      "\n",
      "Detailed Phishing Email Breakdown:\n",
      "- Emails with URLs and Attachments: 12\n",
      "- Emails without URLs but with Attachments: 16\n",
      "- Emails with URLs but without Attachments: 9989\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file = \"data/test_email.csv\"\n",
    "df = pd.read_csv(csv_file, low_memory=False)\n",
    "\n",
    "phish_df = df.query(\"mail_is_safe == 0\")\n",
    "safe_df = df.query(\"mail_is_safe == 1\")\n",
    "\n",
    "print(f\"Phishing Emails: {(phish_df['mail_is_safe'] == 0).sum()}\")\n",
    "print(f\"1. With URLs: {phish_df['has_url'].sum()}\")\n",
    "print(f\"2. Without URLs: {(phish_df['has_url'] == 0).sum()}\")\n",
    "print(f\"3. With Attachments: {phish_df['has_attachment'].sum()}\")\n",
    "print(f\"4. Without Attachments: {(phish_df['has_attachment'] == 0).sum()}\")\n",
    "\n",
    "print(f\"\\nSafe Emails: {(safe_df['mail_is_safe'] == 1).sum()}\")\n",
    "print(f\"1. With URLs: {safe_df['has_url'].sum()}\")\n",
    "print(f\"2. Without URLs: {(safe_df['has_url'] == 0).sum()}\")\n",
    "print(f\"3. With Attachments: {safe_df['has_attachment'].sum()}\")\n",
    "print(f\"4. Without Attachments: {(safe_df['has_attachment'] == 0).sum()}\")\n",
    "\n",
    "print(\"\\nDetailed Phishing Email Breakdown:\")\n",
    "print(f\"- Emails with URLs and Attachments: {len(phish_df.query('has_url == 1 and has_attachment == 1'))}\")\n",
    "print(f\"- Emails without URLs but with Attachments: {len(phish_df.query('has_url == 0 and has_attachment == 1'))}\")\n",
    "print(f\"- Emails with URLs but without Attachments: {len(phish_df.query('has_url == 1 and has_attachment == 0'))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a783bab7-04d9-44f6-b3bf-f7b271028ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
